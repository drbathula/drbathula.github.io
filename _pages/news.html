---
layout: archive
title: "Latest Updates!"
permalink: /news/
author_profile: true
---

{% include base_path %}

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications </sectionheading>(representative papers are <span class="highlight">highlighted</span>)<br/>&nbsp;&nbsp;&nbsp;last update: July 2023</td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
<br/>
  
<tr>
  <td width="33%" valign="top" align="center"><a href="https://diffusion-classifier.github.io/">
  <img src="../images/Bioimaging2024.png" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:0px solid black">
    </a></td>
  </a></td>
  <td width="67%" valign="top">
    <p><a href="https://diffusion-classifier.github.io/" id="DIFFCLS">
    <h5>Best Student Paper Award!</h5>
    <heading>Mutually Exclusive Multi-Modal Approach for Parkinsonâ€™s Disease Classification</heading></a><br>
    Arunava Chaudhuria, Abhishek Singh Sambyal and Deepti R. Bathulaa<br>
    Bioimaging 2024
    </p>

    <div class="paper" id="diffcls">
    <a href="https://diffusion-classifier.github.io/">webpage</a> |
    <a href="javascript:toggleblock('diffcls_abs')">abstract</a> |
    <a shape="rect" href="javascript:togglebib('diffcls')" class="togglebib">bibtex</a> |
    <a href="https://arxiv.org/abs/2303.16203">arXiv</a> |
    <a href="https://github.com/diffusion-classifier/diffusion-classifier">code</a>

    <p align="justify"> <i style="display: none;" id="diffcls_abs">The recent wave of large-scale text-to-image diffusion models has dramatically increased our text-based image generation abilities. These models can generate realistic images for a staggering variety of prompts and exhibit impressive compositional generalization abilities. Almost all use cases thus far have solely focused on sampling; however, diffusion models can also provide conditional density estimates, which are useful for tasks beyond image generation. In this paper, we show that the density estimates from large-scale text-to-image diffusion models like Stable Diffusion can be leveraged to perform zero-shot classification without any additional training. Our generative approach to classification, which we call Diffusion Classifier, attains strong results on a variety of benchmarks and outperforms alternative methods of extracting knowledge from diffusion models. Although a gap remains between generative and discriminative approaches on zero-shot recognition tasks, we find that our diffusion-based approach has stronger multimodal relational reasoning abilities than competing discriminative approaches. Finally, we use Diffusion Classifier to extract standard classifiers from class-conditional diffusion models trained on ImageNet. Even though these models are trained with weak augmentations and no regularization, they approach the performance of SOTA discriminative classifiers. Overall, our results are a step toward using generative over discriminative models for downstream tasks.</i></p>

<pre xml:space="preserve" style="display:none;">
@inproceedings{li2023diffusion,
  title={Your Diffusion Model is
  Secretly a Zero-Shot Classifier},
  author={Li, Alexander C and Prabhudesai,
  Mihir and Duggal, Shivam and Brown,
  Ellis and Pathak, Deepak},
  booktitle={ICCV},
  year={2013}
}
</pre>
    </div>
  </td>
</tr>

</table>
