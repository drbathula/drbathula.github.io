---
layout: archive
title: "Latest Updates!"
permalink: /news/
author_profile: true
---

{% include base_path %}

<table width="100%" align="center" border="0" border-spacing="0" cellspacing="0" cellpadding="15">
<br/>
  
<tr>
  <td width="33%" valign="top" align="center"><a href="https://diffusion-classifier.github.io/">
  <img src="../images/Bioimaging2024.png" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
    </a></td>
  </a></td>
  <td width="67%" valign="top">
    <h2>Best Student Paper Award!</h2>
    <p><a href="https://diffusion-classifier.github.io/" id="MEMMPD">
    <heading>Mutually Exclusive Multi-Modal Approach for Parkinsonâ€™s Disease Classification</heading></a><br>
    Arunava Chaudhuria, Abhishek Singh Sambyal and Deepti R. Bathula<br>
    <em>Bioimaging 2024</em>
    </p>

    <div class="paper" id="MEMMPD">
    <a href="https://diffusion-classifier.github.io/">webpage</a> |
    <a href="javascript:toggleblock('diffcls_abs')">abstract</a> |
    <a shape="rect" href="javascript:togglebib('diffcls')" class="togglebib">bibtex</a> |
    <a href="https://arxiv.org/abs/2303.16203">arXiv</a> |
    <a href="https://github.com/diffusion-classifier/diffusion-classifier">code</a>

    <p align="justify"> <i style="display: none;" id="diffcls_abs">The recent wave of large-scale text-to-image diffusion models has dramatically increased our text-based image generation abilities. These models can generate realistic images for a staggering variety of prompts and exhibit impressive compositional generalization abilities. Almost all use cases thus far have solely focused on sampling; however, diffusion models can also provide conditional density estimates, which are useful for tasks beyond image generation. In this paper, we show that the density estimates from large-scale text-to-image diffusion models like Stable Diffusion can be leveraged to perform zero-shot classification without any additional training. Our generative approach to classification, which we call Diffusion Classifier, attains strong results on a variety of benchmarks and outperforms alternative methods of extracting knowledge from diffusion models. Although a gap remains between generative and discriminative approaches on zero-shot recognition tasks, we find that our diffusion-based approach has stronger multimodal relational reasoning abilities than competing discriminative approaches. Finally, we use Diffusion Classifier to extract standard classifiers from class-conditional diffusion models trained on ImageNet. Even though these models are trained with weak augmentations and no regularization, they approach the performance of SOTA discriminative classifiers. Overall, our results are a step toward using generative over discriminative models for downstream tasks.</i></p>

<pre xml:space="preserve" style="display:none;">
@inproceedings{li2023diffusion,
  title={Your Diffusion Model is
  Secretly a Zero-Shot Classifier},
  author={Li, Alexander C and Prabhudesai,
  Mihir and Duggal, Shivam and Brown,
  Ellis and Pathak, Deepak},
  booktitle={ICCV},
  year={2013}
}
</pre>
    </div>
  </td>
</tr>

<tr>
  <td width="33%" valign="top" align="center"><a href="https://diffusion-classifier.github.io/">
  <img src="../images/ISBI2024.png" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
    </a></td>
  </a></td>
  <td width="67%" valign="top">
    <h2>Accepted to ISBI 2024!</h2>
    <p><a href="https://diffusion-classifier.github.io/" id="WAVEKD">
    <heading>Wavelet-Based Feature Compression For Improved Knowledge Distillation</heading></a><br>
    Usma Niyaz, Abhishek Singh Sambyal and Deepti R. Bathula<br>
    <em>21st IEEE International Symposium on Biomedical Imaging 2024</em>
    </p>

    <div class="paper" id="WAVEKD">
    <a href="https://diffusion-classifier.github.io/">webpage</a> |
    <a href="javascript:toggleblock('wavekd_abs')">abstract</a> |
    <a shape="rect" href="javascript:togglebib('diffcls')" class="togglebib">bibtex</a> |
    <a href="https://arxiv.org/abs/2303.16203">arXiv</a> |
    <a href="https://github.com/diffusion-classifier/diffusion-classifier">code</a>

    <p align="justify"> <i style="display: none;" id="wavekd_abs">Deep learning (DL) models can achieve state-of-the-art performance but at the cost of high computation and memory requirements. Due to their large capacity, DL models have the tendency to learn redundant features. In this work, we exploit this redundancy to improve model compression. Knowledge distillation (KD) aims to achieve model compression by transferring knowledge from a large, complex model to a simple, lightweight model. We propose an enhanced KD strategy that improves the efficiency of the distillation process by compressing the feature maps using Discrete Wavelet Transformation DWT, which helps capture crucial features from complex biomedical signals. Retaining and sharing only the most informative and discriminating features facilitates more effective feature mimicking. Extensive experiments using two benchmark datasets for Melanoma and Histopathology image classification tasks demonstrate the superiority of our proposed method over existing techniques. We further establish the generalizability and robustness of our method using two different teacher-student architectures and ablation studies.</i></p>

<pre xml:space="preserve" style="display:none;">
@inproceedings{li2023diffusion,
  title={Your Diffusion Model is
  Secretly a Zero-Shot Classifier},
  author={Li, Alexander C and Prabhudesai,
  Mihir and Duggal, Shivam and Brown,
  Ellis and Pathak, Deepak},
  booktitle={ICCV},
  year={2013}
}
</pre>
    </div>
  </td>
</tr>
  
</table>
